# SpongeBob LLM ğŸ§½

[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-grey?style=for-the-badge&logo=huggingface)](https://huggingface.co/docs/transformers/index)

**SpongeBob** æ˜¯ä¸€ä¸ªä»é›¶å¼€å§‹å®ç°ã€è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¡¹ç›®ï¼Œå…·å¤‡å®Œæ•´çš„è®­ç»ƒæµæ°´çº¿å’Œç”Ÿäº§çº§ç‰¹æ€§ã€‚é¡¹ç›®å±•ç¤ºäº†ç°ä»£LLMä»é¢„è®­ç»ƒåˆ°éƒ¨ç½²çš„å…¨æµç¨‹å®ç°ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ—ï¸ å®Œæ•´çš„è®­ç»ƒæµç¨‹
- **ä¸‰é˜¶æ®µè®­ç»ƒ**: é¢„è®­ç»ƒ (Pretrain) â†’ æœ‰ç›‘ç£å¾®è°ƒ (SFT) â†’ çŸ¥è¯†è’¸é¦ (Distill)
- **ç”Ÿäº§çº§è®­ç»ƒç³»ç»Ÿ**: å®Œæ•´çš„checkpointä¿å­˜/æ¢å¤ã€æ¢¯åº¦ç´¯ç§¯ã€æ··åˆç²¾åº¦è®­ç»ƒ
- **çµæ´»çš„é…ç½®ç®¡ç†**: ç»Ÿä¸€çš„é…ç½®ç³»ç»Ÿæ”¯æŒä¸åŒè§„æ¨¡çš„æ¨¡å‹å®éªŒ

### ğŸ”§ å…ˆè¿›çš„æ¨¡å‹æ¶æ„
- **æ—‹è½¬ä½ç½®ç¼–ç  (RoPE)**: æ”¯æŒé•¿åºåˆ—å»ºæ¨¡ï¼Œæ›´å¥½çš„ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
- **åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (GQA)**: ä¼˜åŒ–æ¨ç†æ•ˆç‡ï¼Œå‡å°‘KVç¼“å­˜å†…å­˜å ç”¨
- **RMSNorm + SwiGLU**: ç°ä»£å½’ä¸€åŒ–å’Œæ¿€æ´»å‡½æ•°ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§
- **æƒé‡å…±äº«**: åµŒå…¥å±‚ä¸è¾“å‡ºå±‚å‚æ•°å…±äº«ï¼Œå‡å°‘æ¨¡å‹å‚æ•°é‡

### ğŸ“Š ä¼ä¸šçº§å·¥å…·é“¾
- **å®Œæ•´çš„è¯„ä¼°ä½“ç³»**: åŒ…å«PPLè¯„ä¼°ã€äº¤äº’å¼æµ‹è¯•ã€åŸºå‡†æµ‹è¯•
- **å¯è§†åŒ–ç›‘æ§**: æ”¯æŒè®­ç»ƒè¿‡ç¨‹å®æ—¶ç›‘æ§å’ŒæŒ‡æ ‡è¿½è¸ª
- **æ¨¡å‹æœåŠ¡åŒ–**: å‡†å¤‡å°±ç»ªçš„APIæ¥å£ï¼ˆæœªå®Œæˆï¼‰å’Œéƒ¨ç½²æ–¹æ¡ˆ

## ğŸ—‚ é¡¹ç›®æ¶æ„

```
spongebob-llm/
â”œâ”€â”€ Config.py               # æ¨¡å‹é…ç½®ç±» (LLMConfig)
â”œâ”€â”€ model.py                # æ¨¡å‹æ ¸å¿ƒæ¶æ„ (SpongeBob, Attention, RMSNorm etc.)
â”œâ”€â”€ dataset.py              # æ•°æ®é›†åŠ è½½å™¨ (PretrainDataset, SFTDataset)
â”œâ”€â”€ train_tokenizer.py      # è®­ç»ƒtokenizerè„šæœ¬
â”œâ”€â”€ pretrain.py             # é¢„è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒcheckpointæ¢å¤ï¼‰
â”œâ”€â”€ SFT.py                  # æœ‰ç›‘ç£å¾®è°ƒè„šæœ¬ï¼ˆæ”¯æŒcheckpointæ¢å¤ï¼‰
â”œâ”€â”€ distill.py              # çŸ¥è¯†è’¸é¦è„šæœ¬ï¼ˆæ”¯æŒcheckpointæ¢å¤ï¼‰
â”œâ”€â”€ chat.py                 # äº¤äº’å¼å¯¹è¯ç•Œé¢
â”œâ”€â”€ api_server.py           # RESTful APIæœåŠ¡ï¼ˆå¾…å®ç°ï¼‰
â”œâ”€â”€ eval_ppl.py             # å›°æƒ‘åº¦è¯„ä¼°è„šæœ¬
â”œâ”€â”€ results/                # æ¨¡å‹æƒé‡å’Œcheckpointä¿å­˜ç›®å½•
â””â”€â”€ spongebob_tokenizer/    # åˆ†è¯å™¨ç›®å½•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/SpongeBob_Project.git
cd SpongeBob_Project

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å‡†å¤‡åˆ†è¯å™¨ï¼ˆå°†HuggingFaceæ ¼å¼çš„åˆ†è¯å™¨æ”¾å…¥ç›®å½•ï¼‰
cp -r your_tokenizer_directory ./spongebob_tokenizer/
```

### æ•°æ®å‡†å¤‡

**é¢„è®­ç»ƒæ•°æ®æ ¼å¼** (`pretrain.jsonl`):
```json
{"text": "é•¿æ–‡æœ¬å†…å®¹..."}
```

**SFTæ•°æ®æ ¼å¼** (`sft_data.jsonl`):
```json
{"conversations": [{"role": "user", "content": "é—®é¢˜"}, {"role": "assistant", "content": "å›ç­”"}]}
```

### è®­ç»ƒæµç¨‹

#### 1. é¢„è®­ç»ƒé˜¶æ®µ
```bash
python pretrain.py \
    --data_path datasets/pretrain.jsonl \
    --batch_size 80 \
    --learning_rate 5e-4 \
    --max_seq_len 512 \
    --save_dir results \
    --epochs 10 \
    --save_step 1000

# ä»checkpointæ¢å¤è®­ç»ƒ
python pretrain.py --resume_from results/latest_checkpoint.pth --epochs 15
```

#### 2. æœ‰ç›‘ç£å¾®è°ƒ
```bash
python SFT.py \
    --data_path datasets/sft_data.jsonl \
    --pretrained_path results/pretrain_final.pth \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --max_seq_len 1024 \
    --epochs 3
```

#### 3. çŸ¥è¯†è’¸é¦
```bash
python distill.py \
    --data_path datasets/distill_data.jsonl \
    --sft_path results/sft_final.pth \
    --batch_size 16 \
    --learning_rate 1e-6 \
    --special_token_weight 5.0
```

### æ¨¡å‹è¯„ä¼°

#### å›°æƒ‘åº¦è¯„ä¼°
```bash
python eval_ppl.py \
    --model_path results/sft_final.pth \
    --dataset_path datasets/eval_data.jsonl \
    --batch_size 8 \
    --output_file results/ppl_results.json
```

#### äº¤äº’å¼æµ‹è¯•
```bash
python eval_model.py \
    --model_mode 1 \          # 0:é¢„è®­ç»ƒ 1:SFT 2:è’¸é¦
    --save_dir results \
    --temperature 0.7 \
    --top_p 0.9 \
    --max_seq_len 2048
```

## âš™ï¸ é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®
åœ¨ `Config.py` ä¸­çµæ´»è°ƒæ•´æ¨¡å‹æ¶æ„ï¼š

```python
config = LLMConfig(
    dim=512,                  # éšè—å±‚ç»´åº¦
    n_layers=8,               # Transformerå±‚æ•°
    n_heads=8,                # æ³¨æ„åŠ›å¤´æ•°
    n_kv_heads=8,             # KVå¤´æ•°ï¼ˆGQAï¼‰
    vocab_size=64000,         # è¯è¡¨å¤§å°
    max_seq_len=8192,         # æœ€å¤§åºåˆ—é•¿åº¦
    dropout=0.1,              # Dropoutç‡
    rope_theta=10000,         # RoPEåŸºé¢‘
    norm_eps=1e-5,           # å½’ä¸€åŒ–epsilon
)
```

### è®­ç»ƒé…ç½®
æ”¯æŒä¸°å¯Œçš„è®­ç»ƒå‚æ•°è°ƒèŠ‚ï¼š
- **å­¦ä¹ ç‡è°ƒåº¦**: ä½™å¼¦é€€ç« + çº¿æ€§warmup
- **æ¢¯åº¦å¤„ç†**: æ¢¯åº¦ç´¯ç§¯ã€æ¢¯åº¦è£å‰ª
- **ç²¾åº¦æ§åˆ¶**: BF16/FP16æ··åˆç²¾åº¦è®­ç»ƒ
- **å†…å­˜ä¼˜åŒ–**: æ¿€æ´»checkpointingã€æ¢¯åº¦æ£€æŸ¥ç‚¹

## ğŸ“Š ç›‘æ§ä¸å¯è§†åŒ–

### è®­ç»ƒç›‘æ§
é¡¹ç›®é›†æˆå¤šç§ç›‘æ§æ–¹æ¡ˆï¼š

```bash
# ä½¿ç”¨SwanLabï¼ˆé»˜è®¤ï¼‰
python pretrain.py --use_wandb=True

# æˆ–ä½¿ç”¨TensorBoard
tensorboard --logdir results/tensorboard_logs
```

### è¯„ä¼°æŒ‡æ ‡
- **è®­ç»ƒæŸå¤±æ›²çº¿**: å®æ—¶ç›‘æ§æ”¶æ•›æƒ…å†µ
- **å­¦ä¹ ç‡å˜åŒ–**: å¯è§†åŒ–è°ƒåº¦ç­–ç•¥æ•ˆæœ
- **å›°æƒ‘åº¦æŒ‡æ ‡**: é‡åŒ–æ¨¡å‹è¯­è¨€å»ºæ¨¡èƒ½åŠ›
- **ç”Ÿæˆè´¨é‡**: äººå·¥è¯„ä¼°å¯¹è¯æµç•…åº¦

## ğŸ­ ç”Ÿäº§éƒ¨ç½²

### APIæœåŠ¡(æœªå®Œæˆ)
```python
# å¯åŠ¨æ¨¡å‹æœåŠ¡
python api_server.py \
    --model_path results/sft_final.pth \
    --port 8080 \
    --workers 4
```

### æ€§èƒ½ä¼˜åŒ–
- **é‡åŒ–æ¨ç†**: æ”¯æŒINT8/INT4é‡åŒ–ï¼Œå‡å°‘å†…å­˜å ç”¨
- **æ‰¹å¤„ç†ä¼˜åŒ–**: åŠ¨æ€æ‰¹å¤„ç†ï¼Œæé«˜ååé‡
- **ç¼“å­˜æœºåˆ¶**: KVç¼“å­˜ä¼˜åŒ–ï¼Œé™ä½è®¡ç®—å¼€é”€

## ğŸ”¬ æŠ€æœ¯æ·±åº¦

### æ ¸å¿ƒåˆ›æ–°ç‚¹
1. **å®Œæ•´çš„è®­ç»ƒç³»ç»Ÿ**: ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆ
2. **ç”Ÿäº§çº§å¯é æ€§**: å®Œå–„çš„checkpointç®¡ç†å’Œé”™è¯¯æ¢å¤æœºåˆ¶
3. **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªç»„ä»¶éƒ½å¯ç‹¬ç«‹æ›¿æ¢å’Œæ‰©å±•
4. **æ€§èƒ½ä¼˜åŒ–**: é’ˆå¯¹è®­ç»ƒå’Œæ¨ç†çš„å¤šå±‚æ¬¡ä¼˜åŒ–ç­–ç•¥

### æ¶æ„ä¼˜åŠ¿
- **å¯æ‰©å±•æ€§**: æ”¯æŒä»ç™¾ä¸‡å‚æ•°åˆ°åäº¿å‚æ•°çº§åˆ«çš„æ¨¡å‹
- **å¯å¤ç°æ€§**: å®Œæ•´çš„å®éªŒè®°å½•å’Œé…ç½®ç®¡ç†
- **å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„ä»£ç ç»“æ„å’Œå®Œæ•´çš„æ–‡æ¡£

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼

### å¼€å‘æµç¨‹
1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

### ä»£ç è§„èŒƒ
- éµå¾ªPEP 8ç¼–ç è§„èŒƒ
- æ·»åŠ é€‚å½“çš„ç±»å‹æ³¨è§£
- ç¼–å†™å•å…ƒæµ‹è¯•å’Œæ–‡æ¡£
- ç¡®ä¿å‘åå…¼å®¹æ€§

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åœ¨å®ç°è¿‡ç¨‹ä¸­å‚è€ƒäº†ä»¥ä¸‹ä¼˜ç§€å¼€æºé¡¹ç›®ï¼š
- [Llama](https://github.com/facebookresearch/llama) - Metaçš„LLaMAæ¨¡å‹
- [Transformers](https://github.com/huggingface/transformers) - Hugging Face transformersåº“
- [Nanotron](https://github.com/huggingface/nanotron) - è½»é‡çº§è®­ç»ƒæ¡†æ¶

---

**SpongeBob LLM** - è®©æ¯ä¸ªäººéƒ½èƒ½ç†è§£å’Œæ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹ ğŸš€